{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n",
      "Loaded vgg16 model\n"
     ]
    }
   ],
   "source": [
    "'''Code for fine-tuning Inception V3 for a new task.\n",
    "\n",
    "Start with Inception V3 network, not including last fully connected layers.\n",
    "\n",
    "Train a simple fully connected layer on top of these.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "import inception_v3 as inception\n",
    "import vgg16 as VGG\n",
    "import prepare.collect as pc\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "set_session(tf.Session(config=config))\n",
    "'''\n",
    "N_CLASSES = 2\n",
    "IMSIZE = (224, 224)\n",
    "\n",
    "XML_DIR = \"../data/annotations/xmls/\"\n",
    "IMG_DIR = \"../data/images/\"\n",
    "VAL_RATIO = 0.3\n",
    "\n",
    "# TO DO:: Replace these with paths to the downloaded data.\n",
    "# Training directory\n",
    "# train_dir = '../data/catdog/train'\n",
    "# Testing directory\n",
    "# test_dir = '../data/catdog/validation'\n",
    "\n",
    "\n",
    "# Start with an Inception V3 model, not including the final softmax layer.\n",
    "base_model = VGG.VGG16(weights='imagenet')\n",
    "print ('Loaded vgg16 model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn off training on base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "# Add on new fully connected layers for the output classes.\n",
    "# x = Dense(1024, activation='relu')(base_model.get_layer('fc2').output)\n",
    "# x = Dropout(0.5)(x)\n",
    "# predictions = Dense(N_CLASSES, activation='softmax', name='predictions')(x)\n",
    "base_model_last = base_model.get_layer('flatten').output\n",
    "x = Dense(4096, activation='relu', name='fc1-1')(base_model_last)\n",
    "x = Dense(4096, activation='relu', name='fc1-2')(x)\n",
    "predictions = Dense(N_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# y = Dense(4096, activation='relu', name='fc2-1')(base_model_last)\n",
    "# y = Dense(4096, activation='relu', name='fc2-2')(y)\n",
    "# aux_predictions = Dense(4, name='aux_predictions')(y)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show some debug output\n",
    "print (model.summary())\n",
    "\n",
    "print ('Trainable weights')\n",
    "#model.save_weights('catdog_pretrain.h5')\n",
    "#print (model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmlFiles = pc.listAllFiles(XML_DIR)\n",
    "infoList = list(map(lambda f:pc.getInfoTupleForXml(f,IMG_DIR) ,xmlFiles))\n",
    "\n",
    "random.shuffle(infoList)\n",
    "cutIndex = int(len(infoList)*VAL_RATIO)\n",
    "train_files=infoList[:cutIndex]\n",
    "val_files = infoList[cutIndex:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#print(val_files)\n",
    "np.random.seed()\n",
    "img_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def to_categorical(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "    # Returns\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "def my_load_img(img_path,img_datagen,size):\n",
    "    img = image.load_img(img_path, target_size=size)\n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "#     x = img_datagen.img_to_array(img)\n",
    "    x = img_datagen.random_transform(x)\n",
    "    x = img_datagen.standardize(x)\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "def my_img_generator(files,img_datagen,batch_size):\n",
    "#     index_array = np.random.permutation(len(files))\n",
    "    \n",
    "    index = 0\n",
    "    count = 0\n",
    "    img_datas=[]\n",
    "    img_labels=[]\n",
    "    while 1:\n",
    "        # create numpy arrays of input data\n",
    "        # and labels, from each line in the file\n",
    "        if count < batch_size:\n",
    "                img_datas.append(my_load_img(files[index][1],img_datagen,IMSIZE))\n",
    "#                 lable=[0.0,0.0]\n",
    "#                 lable[files[index][1]]=1.0\n",
    "                img_labels.append(files[index][2])\n",
    "                index=(index+1)%len(files)\n",
    "                count+=1\n",
    "        else:\n",
    "            count=0\n",
    "            #print(img_datas)\n",
    "            one_hot_labels=to_categorical(img_labels, num_classes=2)\n",
    "            yield (np.array(img_datas),np.array(one_hot_labels))\n",
    "            img_datas = []\n",
    "            img_labels = []\n",
    "#             random.shuffle(files)\n",
    "            \n",
    "\n",
    "batch_size=32\n",
    "# t = next(my_img_generator(train_files,img_datagen,batch_size))\n",
    "\n",
    "# model.load_weights('catdog_pretrain_nf.h5') \n",
    "# train_data\n",
    "# train_data.shape\n",
    "my_train_generator = my_img_generator(train_files,img_datagen,batch_size)\n",
    "my_val_generator = my_img_generator(val_files,img_datagen,batch_size)\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_dir,  # this is the target directory\n",
    "#         target_size=IMSIZE,  # all images will be resized to 299x299 Inception V3 input\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#         test_dir,  # this is the target directory\n",
    "#         target_size=IMSIZE,  # all images will be resized to 299x299 Inception V3 input\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "\n",
    "# print(a[1].shape)\n",
    "# print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 0.4679 - acc: 0.8047 - val_loss: 0.5358 - val_acc: 0.7578\n",
      "Epoch 2/10\n",
      "3s - loss: 0.5592 - acc: 0.6875 - val_loss: 0.5218 - val_acc: 0.8438\n",
      "Epoch 3/10\n",
      "3s - loss: 0.5300 - acc: 0.7422 - val_loss: 0.4943 - val_acc: 0.8281\n",
      "Epoch 4/10\n",
      "3s - loss: 0.4265 - acc: 0.8203 - val_loss: 0.3984 - val_acc: 0.8125\n",
      "Epoch 5/10\n",
      "3s - loss: 0.3731 - acc: 0.8359 - val_loss: 0.5175 - val_acc: 0.7344\n",
      "Epoch 6/10\n",
      "3s - loss: 0.4237 - acc: 0.7734 - val_loss: 1.3898 - val_acc: 0.6875\n",
      "Epoch 7/10\n",
      "3s - loss: 0.7147 - acc: 0.7812 - val_loss: 0.3931 - val_acc: 0.8281\n",
      "Epoch 8/10\n",
      "3s - loss: 0.3384 - acc: 0.8438 - val_loss: 0.4568 - val_acc: 0.8281\n",
      "Epoch 9/10\n",
      "3s - loss: 0.5387 - acc: 0.7109 - val_loss: 0.5457 - val_acc: 0.6484\n",
      "Epoch 10/10\n",
      "3s - loss: 0.3731 - acc: 0.8594 - val_loss: 0.3848 - val_acc: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d65cca8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# my_train_generator = my_img_generator(train_files,img_datagen,32)\n",
    "# my_val_generator = my_img_generator(val_files,img_datagen,32)\n",
    "# model.fit_generator(\n",
    "#         my_train_generator,\n",
    "#         samples_per_epoch=128,\n",
    "#         nb_epoch=10,\n",
    "#         validation_data=test_datagen,\n",
    "#         verbose=2,\n",
    "#         nb_val_samples=128)\n",
    "model.fit_generator(\n",
    "        my_train_generator,\n",
    "        samples_per_epoch=128,\n",
    "        nb_epoch=10,\n",
    "        validation_data=my_val_generator,\n",
    "        verbose=2,\n",
    "        nb_val_samples=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('catdog_pretrain_nf.h5') \n",
    "# Data generators for feeding training/testing images to the model.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # this is the target directory\n",
    "        target_size=IMSIZE,  # all images will be resized to 299x299 Inception V3 input\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,  # this is the target directory\n",
    "        target_size=IMSIZE,  # all images will be resized to 299x299 Inception V3 input\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=128,\n",
    "        nb_epoch=10,\n",
    "        validation_data=test_generator,\n",
    "        verbose=2,\n",
    "        nb_val_samples=128)\n",
    "#model.save_weights('catdog_pretrain_nf.h5')  # always save your weights after training or during training\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_path = '../data/sport3/validation/hockey/img_2997.jpg'\n",
    "#img_path = '../data/catdog/test/2.jpg'\n",
    "img = image.load_img(img_path, target_size=IMSIZE)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "x = inception.preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', preds)\n",
    "#classes= model.predict_classes(x)\n",
    "#print('Classes:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.load_weights('catdog_pretrain.h5') \n",
    "#img_path = '../data/sport3/validation/hockey/img_2997.jpg'\n",
    "img_path = '../data/cat2.jpg'\n",
    "img_path = '../data/catdog/test/58.jpg'\n",
    "img = image.load_img(img_path, target_size=IMSIZE)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "x = inception.preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', preds)\n",
    "#classes= model.predict_classes(x)\n",
    "#print('Classes:', classes)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
