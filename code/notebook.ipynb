{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"block1_conv1\", padding=\"same\")`\n",
      "  x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"block1_conv2\", padding=\"same\")`\n",
      "  x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"block2_conv1\", padding=\"same\")`\n",
      "  x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"block2_conv2\", padding=\"same\")`\n",
      "  x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"block3_conv1\", padding=\"same\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"block3_conv2\", padding=\"same\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:91: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"block3_conv3\", padding=\"same\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:95: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block4_conv1\", padding=\"same\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block4_conv2\", padding=\"same\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:97: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block4_conv3\", padding=\"same\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block5_conv1\", padding=\"same\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:102: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block5_conv2\", padding=\"same\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
      "E:\\workshare\\inception-roi\\code\\vgg16.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block5_conv3\", padding=\"same\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "552361984/553467096 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "'''Code for fine-tuning Inception V3 for a new task.\n",
    "\n",
    "Start with Inception V3 network, not including last fully connected layers.\n",
    "\n",
    "Train a simple fully connected layer on top of these.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "import inception_v3 as inception\n",
    "import vgg16 as VGG\n",
    "import prepare.collect as pc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "set_session(tf.Session(config=config))\n",
    "'''\n",
    "N_CLASSES = 2\n",
    "IMSIZE = (224, 224)\n",
    "\n",
    "XML_DIR = \"../data/annotations/xmls/\"\n",
    "IMG_DIR = \"../data/images/\"\n",
    "VAL_RATIO = 0.3\n",
    "\n",
    "# TO DO:: Replace these with paths to the downloaded data.\n",
    "# Training directory\n",
    "# train_dir = '../data/catdog/train'\n",
    "# Testing directory\n",
    "# test_dir = '../data/catdog/validation'\n",
    "\n",
    "\n",
    "# Start with an Inception V3 model, not including the final softmax layer.\n",
    "base_model = VGG.VGG16(weights='imagenet')\n",
    "print ('Loaded vgg16 model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn off training on base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "# Add on new fully connected layers for the output classes.\n",
    "# x = Dense(1024, activation='relu')(base_model.get_layer('fc2').output)\n",
    "# x = Dropout(0.5)(x)\n",
    "# predictions = Dense(N_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "base_model_last = base_model.get_layer('flatten').output\n",
    "x = Dense(4096, activation='relu', name='fc1-1')(base_model_last)\n",
    "x = Dense(4096, activation='relu', name='fc1-2')(x)\n",
    "x = Dropout(0.5,  name='dp1-1')(x)\n",
    "predictions = Dense(N_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# model = Model(input=base_model.input, output=predictions)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "y = Dense(4096, activation='relu', name='fc2-1')(base_model_last)\n",
    "y = Dense(4096, activation='linear', name='fc2-2')(y)\n",
    "y = Dropout(0.5,  name='dp2-1')(y)\n",
    "aux_predictions = Dense(4, activation='linear', name='aux_predictions')(y)\n",
    "\n",
    "#model = Model(input=base_model.input, output=predictions)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model = Model(input=base_model.input, output=[predictions, aux_predictions])\n",
    "\n",
    "#not training bbox part\n",
    "model.get_layer(\"fc1-1\").trainable=False\n",
    "model.get_layer(\"fc1-2\").trainable=False\n",
    "model.get_layer(\"predictions\").trainable=False\n",
    "\n",
    "#model.get_layer(\"block5_conv2\").trainable=True;\n",
    "#adam = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss={'predictions': 'categorical_crossentropy', 'aux_predictions': 'mean_squared_error'},\n",
    "             loss_weights={'predictions': 0, 'aux_predictions': 1}, metrics=['accuracy'])\n",
    "\n",
    "# model = Model(input=base_model.input, output=aux_predictions)\n",
    "# model.load_weights('catdog_combine.h5',by_name=True) \n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show some debug output\n",
    "print (model.summary())\n",
    "\n",
    "# print ('Trainable weights')\n",
    "#model.save_weights('catdog_pretrain.h5')\n",
    "\n",
    "#print (model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for oxford dataset\n",
    "xmlFiles = pc.listAllFiles(XML_DIR)\n",
    "infoList = list(map(lambda f:pc.getInfoTupleForXml(f,IMG_DIR) ,xmlFiles))\n",
    "\n",
    "random.shuffle(infoList)\n",
    "cutIndex = int(len(infoList)*VAL_RATIO)\n",
    "train_files_ox = infoList[:cutIndex]\n",
    "val_files_ox = infoList[cutIndex:]\n",
    "#------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for kaggle dataset\n",
    "KAGGLE_TRAIN_DIR=\"../../Mind/A3/data/catdog/train/\"\n",
    "KAGGLE_VAL_DIR=\"../../Mind/A3/data/catdog/validation/\"\n",
    "def processKaggleFolder(imgDir, label):\n",
    "    files = pc.listAllFiles(imgDir)\n",
    "    files = list(map(lambda f:[0,f,label,(50,50,50,50)],files))\n",
    "    return files\n",
    "catfiles_train=processKaggleFolder (KAGGLE_TRAIN_DIR+\"cat/\",0)\n",
    "dogfiles_train =processKaggleFolder (KAGGLE_TRAIN_DIR+\"dog/\",1)\n",
    "train_files_kaggle = catfiles_train + dogfiles_train\n",
    "catfiles_val = processKaggleFolder (KAGGLE_VAL_DIR+\"cat/\",0)\n",
    "dogfiles_val = processKaggleFolder (KAGGLE_VAL_DIR+\"dog/\",1)\n",
    "val_files_kaggle = catfiles_val+dogfiles_val\n",
    "train_files = train_files_ox # + train_files_kaggle\n",
    "val_files = val_files_ox # + val_files_kaggle\n",
    "np.random.seed()\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#print(val_files)\n",
    "#np.random.seed()\n",
    "img_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def to_categorical(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "    # Returns\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "def my_load_img(img_path,img_datagen,size):\n",
    "    img = image.load_img(img_path, target_size=size)\n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "#     x = img_datagen.img_to_array(img)\n",
    "    x = img_datagen.random_transform(x)\n",
    "    x = img_datagen.standardize(x)\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "def my_img_generator(files,img_datagen,batch_size):\n",
    "#     index_array = np.random.permutation(len(files))\n",
    "    \n",
    "    index = 0\n",
    "    count = 0\n",
    "    img_datas=[]\n",
    "    img_labels=[]\n",
    "    img_bboxes=[]\n",
    "    while 1:\n",
    "        # create numpy arrays of input data\n",
    "        # and labels, from each line in the file\n",
    "        if count < batch_size:\n",
    "            img_datas.append(my_load_img(files[index][1],img_datagen,IMSIZE))\n",
    "    #                 lable=[0.0,0.0]\n",
    "    #                 lable[files[index][1]]=1.0\n",
    "            img_labels.append(files[index][2])\n",
    "            \n",
    "            img_bboxes.append(np.array(files[index][3]))\n",
    "            \n",
    "            index=(index+1)%len(files)\n",
    "            count+=1\n",
    "        else:\n",
    "            count=0\n",
    "            #print(img_datas)\n",
    "            one_hot_labels=to_categorical(img_labels, num_classes=2)\n",
    "            #print(img_bboxes)\n",
    "            yield (np.array(img_datas),[np.array(one_hot_labels),np.array(img_bboxes)])\n",
    "                # yield (np.array(img_datas),np.array(img_bboxes))\n",
    "#             else:\n",
    "#                 yield (np.array(img_datas),np.array(one_hot_labels))\n",
    "            img_datas = []\n",
    "            img_labels = []\n",
    "            img_bboxes=[]\n",
    "#             random.shuffle(files)\n",
    "            \n",
    "\n",
    "batch_size=32\n",
    "# t = next(my_img_generator(train_files,img_datagen,batch_size))\n",
    "\n",
    "# model.load_weights('catdog_pretrain_nf.h5') \n",
    "# train_data\n",
    "# train_data.shape\n",
    "my_train_generator = my_img_generator(train_files,img_datagen,batch_size)\n",
    "my_val_generator = my_img_generator(val_files,img_datagen,batch_size)\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_dir,  # this is the target directory\n",
    "#         target_size=IMSIZE,  # all images will be resized to 299x299 Inception V3 input\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#         test_dir,  # this is the target directory\n",
    "#         target_size=IMSIZE,  # all images will be resized to 299x299 Inception V3 input\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#print(next(my_train_generator)[1])\n",
    "# print(a[1].shape)\n",
    "# print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('catdog_combine_3.h5',by_name=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# my_train_generator = my_img_generator(train_files,img_datagen,32)\n",
    "# my_val_generator = my_img_generator(val_files,img_datagen,32)\n",
    "# model.fit_generator(\n",
    "#         my_train_generator,\n",
    "#         samples_per_epoch=128,\n",
    "#         nb_epoch=10,\n",
    "#         validation_data=test_datagen,\n",
    "#         verbose=2,\n",
    "#         nb_val_samples=128)\n",
    "\n",
    "model.fit_generator(\n",
    "        my_train_generator,\n",
    "        samples_per_epoch=128,\n",
    "        nb_epoch=1,\n",
    "        validation_data=my_val_generator,\n",
    "        verbose=2,\n",
    "        nb_val_samples=128)\n",
    "#model.save_weights('catdog_combine_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# img_path = '../data/cat2.jpg'\n",
    "test_img = train_files[0]\n",
    "img_path = test_img[1]\n",
    "# img = image.load_img(img_path, target_size=IMSIZE)\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# x = inception.preprocess_input(x)\n",
    "# x = my_load_img(img_path,img_datagen,IMSIZE)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# preds = model.predict(x)[0]\n",
    "# print('Predicted:', preds)\n",
    "# width=test_img[4][0]\n",
    "# height= test_img[4][1]\n",
    "# actual_preds=[preds[0]*width*0.01,preds[1]*height*0.01,preds[2]*width*0.01,preds[3]*height*0.01]\n",
    "# print('Actual_preds',actual_preds)\n",
    "\n",
    "def getPredForImg(img_path):\n",
    "    x = my_load_img(img_path,img_datagen,IMSIZE)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    return preds\n",
    "def testImage(img_path,preds):  \n",
    "    size = Image.open(img_path).size\n",
    "    width=size[0]\n",
    "    height=size[1]\n",
    "    im = np.array(Image.open(img_path), dtype=np.uint8)\n",
    "    # Create figure and axes\n",
    "    fig,ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(im)\n",
    "    actual_preds=[preds[0]*width*0.01,preds[1]*height*0.01,preds[2]*width*0.01,preds[3]*height*0.01]\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((actual_preds[0],actual_preds[1]),actual_preds[2]-actual_preds[0],actual_preds[3]-actual_preds[1],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    return\n",
    "files = pc.listAllFiles(\"../data/test/\")\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for f in files[60:70]:\n",
    "    preds = getPredForImg(f)\n",
    "    print(preds[0][0])\n",
    "    print('cat' if preds[0][0][0]>0.5 else 'dog')\n",
    "    testImage(f,preds[1][0])\n",
    "    \n",
    "preds = getPredForImg(\"../data/li.jpg\")\n",
    "testImage(\"../data/li.jpg\",preds[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testImg=\"../../Mind/A3/data/catdog/test/31.jpg\"\n",
    "testImg=\"../data/elephant.jpg\"\n",
    "\n",
    "preds = getPredForImg(testImg)\n",
    "print(preds[0][0])\n",
    "print('cat' if preds[0][0][0]>0.5 else 'dog')\n",
    "testImage(testImg,preds[1][0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
